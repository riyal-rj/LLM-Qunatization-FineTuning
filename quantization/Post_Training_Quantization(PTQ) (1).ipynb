{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "w-VEDVvgDTPt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yF3UCLbUDRyM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the datsets"
      ],
      "metadata": {
        "id": "n9kkrkcNDlvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose(\n",
        "    [transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))]\n",
        "\n",
        ")\n",
        "\n",
        "#Load the dataset\n",
        "mnist=datasets.MNIST(root='./data',train=True,download=True,transform=transform)\n",
        "\n",
        "train_dataloader=torch.utils.data.DataLoader(mnist,batch_size=10,shuffle=True)\n",
        "mnist_test=datasets.MNIST(root='./data',train=False,download=True,transform=transform)\n",
        "test_dataloader=torch.utils.data.DataLoader(mnist_test,batch_size=10,shuffle=True)\n",
        "\n",
        "\n",
        "device=\"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2JuyPDUDklP",
        "outputId": "c084e6b8-fdc1-4cb4-ba91-1e6831c112f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 56410636.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1899095.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 13707429.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3570189.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Model"
      ],
      "metadata": {
        "id": "zZvbPPxuFLPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,hidden_size_1=100,hidden_size_2=200):\n",
        "        super(SimpleNet,self).__init__()\n",
        "        self.linear1=nn.Linear(28*28,hidden_size_1)\n",
        "        self.linear2=nn.Linear(hidden_size_1,hidden_size_2)\n",
        "        self.linear3=nn.Linear(hidden_size_2,10)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "    def forward(self,image):\n",
        "        image=image.view(-1,28*28)\n",
        "        image=self.relu(self.linear1(image))\n",
        "        image=self.relu(self.linear2(image))\n",
        "        image=self.linear3(image)\n",
        "        return image"
      ],
      "metadata": {
        "id": "kb1cnZJ9FFf5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net=SimpleNet().to(device)"
      ],
      "metadata": {
        "id": "R9E0C_nBFt9N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "rfwNY6xNF_8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader,net,epoch=5,total_iterations_limit=None):\n",
        "  cross_entropy=nn.CrossEntropyLoss()\n",
        "  optimizer=torch.optim.Adam(net.parameters(),lr=0.001)\n",
        "\n",
        "  total_iters=0\n",
        "  for e in range(epoch):\n",
        "    net.train()\n",
        "    loss_sum=0\n",
        "    num_iters=0\n",
        "\n",
        "    data_iterator=tqdm(train_dataloader,desc=f'Epoch {epoch+1}')\n",
        "    if total_iterations_limit is not None:\n",
        "      data_iterator.total=total_iterations_limit\n",
        "    for data in data_iterator:\n",
        "      num_iters+=1\n",
        "      total_iters+=1\n",
        "      image,label=data\n",
        "      image,label=image.to(device),label.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output=net(image.view(-1,28*28))\n",
        "      loss=cross_entropy(output,label)\n",
        "      loss_sum+=loss.item()\n",
        "      avg_loss=loss_sum/num_iters\n",
        "      data_iterator.set_postfix(loss=avg_loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if total_iterations_limit is not None and total_iters>=total_iterations_limit:\n",
        "        return\n"
      ],
      "metadata": {
        "id": "iRPEwpTyFyzT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
        "    os.remove('temp_delme.p')\n",
        "\n",
        "MODEL_FILENAME = 'simplenet_ptq.pt'\n",
        "\n",
        "if Path(MODEL_FILENAME).exists():\n",
        "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
        "    print('Loaded model from disk')\n",
        "else:\n",
        "    train(train_dataloader, net, epoch=1)\n",
        "    # Save the model to disk\n",
        "    torch.save(net.state_dict(), MODEL_FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZy3-gNIHkXe",
        "outputId": "4e338e2e-f785-488c-a50f-61db25a5e232"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 6000/6000 [01:12<00:00, 82.62it/s, loss=0.215]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model: nn.Module, total_iterations: int = None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    iterations = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_dataloader, desc='Testing'):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x.view(-1, 784))\n",
        "            for idx, i in enumerate(output):\n",
        "                if torch.argmax(i) == y[idx]:\n",
        "                    correct +=1\n",
        "                total +=1\n",
        "            iterations += 1\n",
        "            if total_iterations is not None and iterations >= total_iterations:\n",
        "                break\n",
        "    print(f'Accuracy: {round(correct/total, 3)}')"
      ],
      "metadata": {
        "id": "J-HAX9sBIgoZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before Quantization"
      ],
      "metadata": {
        "id": "M7GVZbRKIMj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights matrix of the model before quantization\n",
        "print('Weights before quantization')\n",
        "print(net.linear1.weight)\n",
        "print(net.linear1.weight.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7GkBNffHlcm",
        "outputId": "bb27e95b-39c0-4a8a-87fd-e84b00df91ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights before quantization\n",
            "Parameter containing:\n",
            "tensor([[ 0.0080,  0.0578,  0.0237,  ...,  0.0003,  0.0079,  0.0556],\n",
            "        [ 0.0396, -0.0197,  0.0119,  ...,  0.0084,  0.0382, -0.0078],\n",
            "        [ 0.0125,  0.0403,  0.0097,  ...,  0.0050, -0.0146, -0.0065],\n",
            "        ...,\n",
            "        [ 0.0320, -0.0159,  0.0083,  ...,  0.0187, -0.0224,  0.0310],\n",
            "        [-0.0153, -0.0110, -0.0316,  ..., -0.0404,  0.0094,  0.0189],\n",
            "        [-0.0277, -0.0152, -0.0175,  ...,  0.0042,  0.0063, -0.0131]],\n",
            "       requires_grad=True)\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of the model before quantization')\n",
        "print_size_of_model(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1-55wAJIS--",
        "outputId": "4351ad88-addd-4f55-d3e1-8fbc87def921"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model before quantization\n",
            "Size (KB): 405.414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy of the model before quantization: ')\n",
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlE711TzIWjC",
        "outputId": "8dc62ceb-0021-4f39-924c-f505617eb848"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model before quantization: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 293.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantized Model"
      ],
      "metadata": {
        "id": "cPziuZq0NeBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantizedVerySimpleNet(nn.Module):\n",
        "    def __init__(self, hidden_size_1=100, hidden_size_2=200):\n",
        "        super(QuantizedVerySimpleNet,self).__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 28*28)\n",
        "        x = self.quant(x)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        x = self.dequant(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-GU7bcjTIZkC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_quantized = QuantizedVerySimpleNet().to(device)\n",
        "# Copy weights from unquantized model\n",
        "net_quantized.load_state_dict(net.state_dict())\n",
        "net_quantized.eval()\n",
        "\n",
        "net_quantized.qconfig = torch.ao.quantization.default_qconfig\n",
        "net_quantized = torch.ao.quantization.prepare(net_quantized) # Insert observers\n",
        "net_quantized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqzKerk1LSEE",
        "outputId": "f4f0f031-1902-43be-c6d3-6a870a93062a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedVerySimpleNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=100, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=100, out_features=200, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=200, out_features=10, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(net_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC7CLJ5lLU9g",
        "outputId": "65000845-6495-4abb-cb0b-9f37badaef80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:04<00:00, 241.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net_quantized = torch.ao.quantization.convert(net_quantized)"
      ],
      "metadata": {
        "id": "-XpWlOJvL5o_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "net_quantized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1nQgUVcM_kH",
        "outputId": "10df569b-538f-45dd-b791-e6b584dfe35c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedVerySimpleNet(\n",
              "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
              "  (linear1): QuantizedLinear(in_features=784, out_features=100, scale=0.5790975689888, zero_point=74, qscheme=torch.per_tensor_affine)\n",
              "  (linear2): QuantizedLinear(in_features=100, out_features=200, scale=0.4156707525253296, zero_point=76, qscheme=torch.per_tensor_affine)\n",
              "  (linear3): QuantizedLinear(in_features=200, out_features=10, scale=0.44545111060142517, zero_point=80, qscheme=torch.per_tensor_affine)\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights matrix of the model after quantization\n",
        "print('Weights after quantization')\n",
        "print(torch.int_repr(net_quantized.linear1.weight()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrugevPdNR6W",
        "outputId": "f59eecc8-1a7a-4a5b-ee87-142ec05c03b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after quantization\n",
            "tensor([[ 2, 13,  5,  ...,  0,  2, 12],\n",
            "        [ 9, -4,  3,  ...,  2,  8, -2],\n",
            "        [ 3,  9,  2,  ...,  1, -3, -1],\n",
            "        ...,\n",
            "        [ 7, -3,  2,  ...,  4, -5,  7],\n",
            "        [-3, -2, -7,  ..., -9,  2,  4],\n",
            "        [-6, -3, -4,  ...,  1,  1, -3]], dtype=torch.int8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compare the Dequantized weights"
      ],
      "metadata": {
        "id": "dTmzy1w_coYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original weights: ')\n",
        "print(net.linear1.weight)\n",
        "print('')\n",
        "print(f'Dequantized weights: ')\n",
        "print(torch.dequantize(net_quantized.linear1.weight()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rwmyq9mNVeW",
        "outputId": "9480e51a-5f5c-4afb-a502-86c1ac8cd126"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weights: \n",
            "Parameter containing:\n",
            "tensor([[ 0.0080,  0.0578,  0.0237,  ...,  0.0003,  0.0079,  0.0556],\n",
            "        [ 0.0396, -0.0197,  0.0119,  ...,  0.0084,  0.0382, -0.0078],\n",
            "        [ 0.0125,  0.0403,  0.0097,  ...,  0.0050, -0.0146, -0.0065],\n",
            "        ...,\n",
            "        [ 0.0320, -0.0159,  0.0083,  ...,  0.0187, -0.0224,  0.0310],\n",
            "        [-0.0153, -0.0110, -0.0316,  ..., -0.0404,  0.0094,  0.0189],\n",
            "        [-0.0277, -0.0152, -0.0175,  ...,  0.0042,  0.0063, -0.0131]],\n",
            "       requires_grad=True)\n",
            "\n",
            "Dequantized weights: \n",
            "tensor([[ 0.0092,  0.0595,  0.0229,  ...,  0.0000,  0.0092,  0.0550],\n",
            "        [ 0.0412, -0.0183,  0.0137,  ...,  0.0092,  0.0366, -0.0092],\n",
            "        [ 0.0137,  0.0412,  0.0092,  ...,  0.0046, -0.0137, -0.0046],\n",
            "        ...,\n",
            "        [ 0.0321, -0.0137,  0.0092,  ...,  0.0183, -0.0229,  0.0321],\n",
            "        [-0.0137, -0.0092, -0.0321,  ..., -0.0412,  0.0092,  0.0183],\n",
            "        [-0.0275, -0.0137, -0.0183,  ...,  0.0046,  0.0046, -0.0137]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of the model after quantization')\n",
        "print_size_of_model(net_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDFQDD3Mcu3r",
        "outputId": "3eb06b37-3415-4655-9b5f-51e0a46e8776"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model after quantization\n",
            "Size (KB): 106.786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Testing the model after quantization')\n",
        "test(net_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6syH78oc6lG",
        "outputId": "23bd8dfc-c612-4de4-9877-531507d92233"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 263.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNnqyrChdEYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}